\bigsection{as Computational Redundancy}
\label{sec:redundancy}%

We can picture a parameterization as an infinite stack of slices.
So far, we have worked under the hypothesis that complexity increases as we ascend through this stack.
As such, parameter values represent levels of complexity.
However, when each slice represents a level of constant complexity, then, relative to their length, the complexity of instances decreases inside each slice.
As the length of instances in a given slice goes up, their relative complexity goes down.

\begin{example}
\label{ex:long_instances}%
  With \cl{FPT}, we consider decidability in polynomial time easy, and use parameter values to express computational complexity beyond polynomial time.
  Thinking of \cl{FPT} as computational complexity up to computability in polynomial time, we can see the importance of the first elements of slices.
  Let~$A$ be a set that is in~\cl{FPT} with a parameterization~$\eta$.
  This means that, for some function~$f$ and polynomial~$p$, membership in~$A$ can be decided in $f(k) \cdot p(\length{x})$ time steps, whenever we have $x \in \eta_k$.
  Now, for those~$x$ and~$k$ that satisfy $\length{x} \ge f(k)$, we have
  \begin{equation*}
    f(k) \cdot p(\length{x}) \le \length{x} \cdot p(\length{x}).
  \end{equation*}
  In other words, for sufficiently long strings~$x$ in a fixed slice $\eta_k$, membership in~$A$ can be decided in polynomial time.
\end{example}

The example above shows that the especially interesting elements of a slice~$\eta_k$ are those of length at most~$f(k)$.
Typically, however, the function~$f$ is rather fast-growing.
Therefore, the observation in the example may not be very effective in distilling the origin of the computational complexity of a set.
There are simply too many strings~$x$ that satisfy $\length{x} \le f(k)$.
In many cases, the computational complexity of a set can be pinpointed to far shorter initial segments of the slices of a parameterization.

\begin{example}[continued from Example~\ref{ex:p-cylinder}]
\label{ex:cylinder-kernel}%
  \indexkey{example!p-cylinder@\pdash{}cylinder}%
  Let $A$ be a \pdash{}cylinder and $g\colon \binary^+ \to \binary^+ \times \binary^+$ a corresponding isomorphism.
  Recall that the parameterization based on $g$ was defined as
  \begin{equation*}
    \eta \deq (\{x \st \asNat(g_1(x)) \le \asNat(k)\})_{k \in \binary^+}.
  \end{equation*}
  In the parameterized decision procedure for~$A$ outlined in Example~\ref{ex:p-cylinder}, only the first component of the image of~$g$ was taken into consideration.
  Thus, if~$g$ maps~$x$ to~$(y, z)$, then the length of~$z$ is largely irrelevant for the computational complexity of deciding membership of~$x$ in~$A$.
  We might as well replace~$z$ with the constant string~\bits{0}.
  Indeed, the string $x' \deq g^{-1}(y, \bits{0})$ is a member of the same slices as~$x$.
  Additionally, we can bound the length of~$x'$, because $g^{-1}$ is polytime-computable.
  In particular, the length of~$x'$ is polynomial in~$y = g_1(x)$.
  Thus for every~$k$ for which we have $x \in \eta_k$, we can bound $\length{x'}$ by a polynomial of~$\length{k}$.
  Equivalently, we can bound~$\length{x'}$ by a polylogarithmic function of~$\asNat(k)$.
\end{example}

In the example above, we sent a string~$x$ to another string~$x'$ in the same slice as~$x$, in a way that preserves membership.
Put differently, we defined a reduction from the set~$A$ to itself that was well-behaved with respect to the parameterization.
The reduction is akin to an \defkey{autoreduction} in the spirit of \textcite{trakhtenbrot1970autoreducibility}.
Where the definition of an autoreduction excludes reducing to the input string, our reduction satisfies a condition that is in some sense stronger.
Namely, our reduction meets a bound, as a function of the parameter value, on the length of the strings to which an input is reduced.
In this light, our reduction can be compared to a more restrictive type of autoreduction, the \defkey{self-reduction}~\parencite{meyer1979with}.
In the textbook treatment by \textcite[Section~4.5]{balcazar1995structural}, self-reducibility is defined as autoreducibility where all strings to which an input is reduced are strictly shorter than the input.
However, many of the results around self-reducibility extend to more general orders than the \enquote{shorter than}-order.
Indeed, the definition of self-reducibility can be generalized to encompass such more general orders \parencite{ko1983self,orponen1986optimal,buhrman1996p-selective}.
Unfortunately, even this generalized definition does not adequately capture the behavior of our reduction in Example~\ref{ex:cylinder-kernel}~\parencite{chen2011lower}.
Reductions of this type form a class of reductions of their own.

One of the reasons this class of reductions is of interest is because of its relationship to \defkey{preprocessing}.
The goal of preprocessing is to eliminate all computational redundancy from an input and identify its computationally hard part.
In the case of Example~\ref{ex:cylinder-kernel}, we could throw away the second component in the image of the isomorphism~$g$.
Crucially, doing so allowed us to reduce the input in polynomial time to an equivalent string of a length that was bounded by a function of the parameter value.
Returning once more to Figure~\ref{fig:length_decomposed}, we see that essentially only the useful information was relevant for deciding membership.
The algorithmic noise could be considered a form of computational redundancy.
Generally, preprocessing may not be so powerful and the image of the reduction may be far longer than the parameter value.
In other words, the length of the result of preprocessing a string~$x$ is not guaranteed to be at most that of~$x$.
However, as long as the length of the result can be bounded by a function of a parameter value for~$x$, the preprocessing has some guarantee on its effectiveness.

\subsubsection{Synopsis}
Preprocessing procedures such as the one introduced in Example~\ref{ex:cylinder-kernel} are formally known as \emph{kernelizations}.
Just like with other forms of reducibility, the definition of a kernelization allows for some variation.
Varying the constraints we place on a kernelization, we can obtain anything from a many--one kernelization to a Turing kernelization.
The spectrum of possible definitions is the topic of Section~\ref{sec:redundancy:types}.
As far as the existence of a kernelization for a set is concerned, there is no difference between the various kinds of kernelization.
We shall see that a set~$A$ has a kernelization of any kind with respect to some given parameterization precisely when $A$ is fixed-parameter tractable.
However, a less constrained kind of kernelization may be able to reduce its inputs to shorter strings than a more constrained kind of kernelization could.
In that sense, the various kinds of kernelization may differ in effectiveness.

The difference between the length of an input string and that of the string to which it is reduced is a measure of the computational redundancy in the input.
Thus, a kernelization is a way to identify a parameterization with the computational redundancy present in the inputs to a decision problem.
A difference in the effectiveness of kernelizations can therefore be interpreted as a difference in the amount of computational redundancy that is recognized.
Typically, a kernelization is considered to be reasonably effective if the length of the reduced strings is polynomial in the numeric parameter value.
In Section~\ref{sec:redundancy:polynomial}, we go into detail about these \emph{polynomial} kernelizations.
We consider the possibility of a relationship between the size of kernelizations and the running time of fixed-parameter tractable decision procedures.
This relationship turns out to be very weak, thus we find that computational tractability and computational redundancy are distinct measures of complexity.

Moreover, we find in Section~\ref{sec:redundancy:polynomial} that the existence of a polynomial kernelization depends on the kind of kernelization we target.
For this finding, we introduce a technique for constructing sets that are kernelizable in one way but not another.
This technique revolves around composing sets as the disjoint union of a hard part and a computationally redundant part that reduces to the hard part.
The same technique is used in Section~\ref{sec:redundancy:hierarchy} to build a fine-grained hierarchy of polynomial kernelizability.
We identify what additional constraints in the definition of a kernelization lead to a strictly smaller class of sets having polynomial kernelizations.
Thus, the levels in our hierarchy correspond to different kinds of polynomial kernelization.
Most of the results concerning the hierarchy are the outcome of a joint work with Ralph Bottesch and Leen Torenvliet~\parencite{witteveen2019hierarchy}.

At one level of our hierarchy of kernelizability, we can reinterpret the computational redundancy identified by a kernelization as related to \enquote{advice}.
With the corresponding definition of a kernelization, more computational redundancy is linked to less advice being needed by a decision procedure.
Specifically, having a polynomial kernelization is conceptually the same as having a decision procedure that takes an advice string of polynomial length.
In Section~\ref{sec:redundancy:advice}, we compare this notion of polynomial advice with the leading notion of polynomial advice in computational complexity theory.
While the traditional notion is shown to have some strong ties with polynomial kernelizability, it is nevertheless different from our new notion of advice.
Neither notion of polynomial advice is stronger than the other.

The level of our hierarchy of kernelizability that represents a notion of advice appears again in Section~\ref{sec:redundancy:lower_bounds}.
In that section, it is shown that an established technique for lower bounding the minimum size of a kernelization can be generalized.
The lower bounding technique was originally used to lower bound the size of the most restrictive kind of kernelizations for certain decision problems.
However, for less constrained kinds of kernelization, the technique works just as well.
We shall see that it generalizes to the kind of polynomial kernelization that we related earlier to a notion of polynomial advice.

\subsection{Types of Kernelization}
\label{sec:redundancy:types}%
In the \citeauthor{flum2006parameterized} framework, a \defkey{kernelization} can be defined as follows.
Let $A$ be a set and $\kappa$ a parameterization in the sense of \citeauthor{flum2006parameterized} as we have seen in Section~\ref{sec:parameterized_complexity_theory}.
A kernelization for~$A$ with respect to~$\kappa$ is a polytime-computable function $\phi\colon \binary^+ \to \binary^+$ that satisfies two properties.
The first property it should satisfy is that for all strings~$x$, we have $x \in A \iff \phi(x) \in A$.
The other property required is that there is some computable function $h\colon \binary^+ \to \bbN$ such that, for all strings~$x$, we have $\length{\phi(x)} \le h(\kappa(x))$.
In other words, a kernelization is a polytime many--one reduction with a length bound on the image in terms of the parameter value of the input.\indexkey{reduction!many--one}

As we shall soon see, kernelizations are closely related to fixed-parameter tractability.
However, there is no reason we should restrict ourselves to many--one reducibility.
This was first observed by \textcite{lokshtanov2009new}, who introduced the more general \emph{Turing kernelization}, where the type of reducibility at play is Turing reducibility.\indexkey{reduction!Turing}
In our framework, this very general form of kernelization can be defined as follows.
\begin{definition}
\label{def:turing_kernelization}%
  Let $\phi$ be a parameterized procedure that can query an oracle about membership of strings in a set~$A$.
  The procedure~$\phi$ is a \defkeyat{kernelization!Turing}{Turing kernelization} for~$A$ with respect to a decidable parameterization~$\eta$ if
  \begin{itemize}
  \item there is a polynomial~$p$ such that $\phi$ terminates on any input string~$x$ within $p(\length{x})$ steps, regardless of the parameter value provided as the second argument to~$\phi$,
  \item $\phi$ converges to~$A$ on~$\eta$, and
  \item there is a computable function~$h\colon \binary^+ \to \bbN$ such that any query made by~$\phi$ on an input $(x, k)$ has a length of at most $h(k)$.
  \end{itemize}
\end{definition}
While the definition may seem daunting, the three items really codify the same properties that were required of traditional kernelizations.
That is, a Turing kernelization runs in polynomial time, decides membership, and obeys a length bound on the queries it makes.

We remark that every Turing kernelization also has a computable upper bound on the minimum length of a parameter value with which a queried string is in~$\eta$.
Because the parameterization~$\eta$ was required to be decidable, the minimization function~$\mu_\eta$ is computable.
This makes the largest minimum length of a parameter value with which any queried string is in~$\eta$,
\begin{equation*}
  \max \{\mu_\eta(q) \st q \in \binary^+ \reland \length{q} \le h(x)\},
\end{equation*}
computable as a function of~$x$.
In fact, the decidability requirement in the definition can be relaxed to the criterion that there exists a computable parameter estimator~$\kappa$ for~$\eta$.
An upper bound to the minimum length of a parameter value for the queries is then found by replacing $\mu_\eta(q)$ by $\length{\kappa(q)}$ in the expression above.

Besides the length bound, more restrictions on the queries made by a Turing kernelization can be put in place.
We observe that in the execution of a Turing kernelization, which string is queried next may depend on the answers of the oracle to queries made previously.
Because of this, a Turing kernelization is said to be \defkeyat{kernelization!adaptive}{adaptive}.
We may restrict a Turing kernelization so that it must determine all the queries it will make at once, before knowing the feedback of any of them.
With this addition of this restriction, we have defined a \defkeyat{kernelization!truth-table}{truth-table kernelization}.\indexkey{reduction!truth-table}
This type of kernelization is relevant in the context of parallelized computation.
As observed by \textcite{weller2013aspects}, the independence of the queries makes it possible to compute their answers in parallel.
This turns truth-table kernelization into a design pattern for parallel algorithms.

Note that, by the bound on its running time, a Turing kernelization can be made to terminate regardless of the oracle it is provided with.
In this regard, Turing kernelizations differ from Turing reductions in \emph{computability} theory \parencite{rogers1967theory,odifreddi1992classical}, which may never stop querying their oracle.
Therefore, a Turing kernelization is really a \emph{bounded Turing kernelization}, or, equivalently, a \emph{weak truth-table kernelization} \parencite{odifreddi1992classical} \parencite[see also][Section~2.4.3]{downey2010algorithmic}.
Even then, the names do not fully describe all properties, as a weak truth-table reduction need not terminate after it has received the answers to its queries.

Examples of Turing kernelizations can be found in the works of \textcite{jansen2017turing,thomasse2017polynomial}, and in the textbook by \textcite[Section~9.4]{cygan2015parameterized}.
While the kernelizations in the first two works are adaptive, the kernelization discussed in the textbook is non-adaptive and thus a truth-table kernelization.
Further examples of both Turing and truth-table kernelizations can be found in the textbook by \textcite{fomin2019kernelization}.

More restrictive still are Turing kernelizations that are only allowed to make a constant number of queries.
Yet, even Turing kernelizations that only make at most one query can do something that traditional many--one kernelizations cannot do.
They can invert the answer they receive from the oracle in their membership decision.
A further restriction we shall consider is related to this ability and was introduced by \textcite{jockusch1968semirecursive} in computability theory and, later, by \textcite{selman1982analogues} in complexity theory.
\begin{definition}
  Let $\phi$ be a parameterized decision procedure that can query an oracle.
  Additionally, denote the set $\phi$ decides when the oracle answers according to a set~$A$ by $\phi_A^{-1}(\bits{1})$.
  The procedure~$\phi$ is \defkeyat{kernelization!positive}{positive} if, for all sets $A$ and $B$ that satisfy $A \subseteq B$, we have $\phi_A^{-1}(\bits{1}) \subseteq \phi_B^{-1}(\bits{1})$.
\end{definition}

The reason for calling kernelizations that behave as in the above definition \enquote{positive} can most easily be seen by looking at positive truth-table kernelizations.
As it turns out, the dependence on the oracle of a positive truth-table kernelization can be expressed as a Boolean formula that does not use negation.
The disjunctive kernelizations and conjunctive kernelizations of \textcite{kratsch2014recent} are examples of positive truth-table kernelizations.

Finally, a positive Turing kernelization that makes at most one query could indeed be called a \defkeyat{kernelization!many--one}{many--one kernelization}.
The oracle access of a many--one kernelization is quite restrictive.
However, such kernelizations are still quite powerful from a computational complexity point of view.

\begin{theorem}
\label{thm:kernel_fpt}%
  The following statements about a decidable set~$A$ and parameterization~$\eta$ are equivalent.
  \begin{enumerate}
  \item\label{enum:kernel:manyone}
    There is a many--one kernelization for~$A$ with respect to~$\eta$.
  \item\label{enum:kernel:turing}
    There is a Turing kernelization for~$A$ with respect to~$\eta$.
  \item\label{enum:kernel:fpt}
    $A$ is in~\cl{FPT} with~$\eta$.
  \end{enumerate}
\end{theorem}
\begin{proof}
$\ref{enum:kernel:manyone} \implies \ref{enum:kernel:turing}$.
  As a many--one kernelization is a restricted form of a Turing kernelization, this implication is immediate.

$\ref{enum:kernel:turing} \implies \ref{enum:kernel:fpt}$.
  Let $\phi$ be the Turing kernelization for~$A$ with respect to~$\eta$ and let $\psi$ be a decision procedure for~$A$.
  Furthermore, let $p$ be the polynomial bounding the running time of~$\phi$ and let $h$ be the function bounding the length of the queries made by~$\phi$.
  We can modify~$\phi$ and turn it into a witness for the fact that $A$ is in~\cl{FPT} with~$\eta$.
  Suppose we want to decide membership of a string~$x$ in~$A$ and are supplied with a parameter value~$k$ such that we have $x \in \eta_k$.
  We run $\phi$ on~$(x, k)$ and whenever~$\phi$ would pose a query to its oracle, instead we make it use~$\psi$ to figure out itself what the oracle would answer.
  Two things we know about the queries $\phi$ makes are that there are at most $p(\length{x})$ of them and that each is bounded in length by~$h(k)$.
  Now, if we denote the running time of~$\psi$ by~$t$, we thus find that the modification to~$\phi$ prolongs its running time by no more than an additional $p(\length{x}) \cdot t(h(k))$ steps.
  Thus, the modified~$\phi$ indeed witnesses that $A$ is in~\cl{FPT} with $\eta$.

$\ref{enum:kernel:fpt} \implies \ref{enum:kernel:manyone}$.
  The core idea for this implication was present already in Example~\ref{ex:long_instances}.
  Let $f$ be the computable function and $p$ the polynomial such that, for all~$x$ and~$k$ with~$x \in \eta_k$, membership of~$x$ in~$A$ can be decided in $f(k) \cdot p(\length{x})$ steps.
  As shown in Example~\ref{ex:long_instances}, membership in~$A$ of sufficiently long instances can be decided in polynomial time without using an oracle.
  This leaves us to define a parameterized decision procedure for instances~$x$ and parameter values~$k$ that satisfy $\length{x} < f(k)$.
  Such membership questions can, however, simply be delegated to the oracle while still satisfying the definition of a many--one kernelization.
\end{proof}

The previous result urges us to look at even more restricted forms of kernelization.
A closer look at Example~\ref{ex:long_instances} tells us that kernelizations show us where the computational complexity in a decision problem resides.
If a set~$A$ has a kernelization with respect to a parameterization~$\eta$, then all computational complexity of~$A$ resides in initial segments of the slices of~$\eta$.
Of course, when we attempt to identify the computationally hard part of the set, we try to keep this hard part as small as possible.
The bound~$h$ in Definition~\ref{def:turing_kernelization} can be used to formalize what \enquote{small} should mean in this case.
Because we are primarily interested in the limiting behavior of~$h$, we shall think of~$h$ not as a function of a parameter value~$k$, but as a function of~$\asNat(k)$.
In many cases, this is quite natural.
For example, with the parameterization defined in Example~\ref{ex:length_parameterization}, the values of~$\asNat(k)$ relate to the lengths of instances.
We say that a Turing kernelization is a \defkeyat{kernelization!polynomial}{polynomial Turing kernelization} if the associated bound~$h$ can be a polynomial of~$\asNat(k)$.
More generally, we refer to the bound as a function of $\asNat(k)$ as the \defkeyat{kernelization!size}{size} of the kernelization.
\begin{example}[continued from Example~\ref{ex:cylinder-kernel}]
  The construction of the previous example lies at the heart of a polynomial many--one kernelization for \pdash{}cylinders.
  For the \pdash{}cylinder~$A$ with isomorphism~$g$ and parameterization~$\eta$, this kernelization would proceed as follows on an input~$(x, k)$.
  First, the procedure would compute $g_1(x)$ and verify that $\asNat(g_1(x)) \le \asNat(k)$ holds.
  If it does not, we do not have $x \in \eta_k$ and the procedure returns~\bits{?}.
  Because $g$ is computable in polynomial time, this can be done in a time that is bounded polynomially in~$\length{x}$.
  When we do have $x \in \eta_k$, the next step of the procedure is to construct $x' = g^{-1}(g_1(x), \bits{0})$.
  As we had seen before, the length~$\length{x'}$ can be bounded by a polylogarithmic function of $\asNat(k)$.
  Finally, the procedure queries the oracle for membership of~$x'$ in~$A$ and returns the answer of the oracle.
  By returning the answer of the oracle, the kernelization ensures it is a positive kernelization.
  As it queries at most one string of a length that can be bounded by a polylogarithmic function, it is a polylogarithmic many--one kernelization.
  Of course, it is also a polynomial many--one kernelization.
\end{example}

Most treatments of kernelization, including the standard textbook of~\textcite{fomin2019kernelization}, require an additional property of the size of a kernelization.
With respect to a parameterization~$\eta$, this additional property is as follows for a kernelization~$\phi$ of size~$h$:
For any query~$q$ that $\phi$ poses to its oracle, there must be a parameter value~$k'$ for which we have $q \in \eta_{k'}$ and $\asNat(k') \le h(\asNat(k))$.
This is a technical restriction that codifies that the queries may not have an overly high complexity.
It is not always imposed \parencite[e.g.][]{flum2006parameterized}, and sometimes relaxed to obtain a notion of \emph{compression}~\parencite{bodlaender2014kernelization}.
With the additional requirement in place, the kernelization in the previous example is no longer a polylogarithmic kernelization.
However, it is still a polynomial kernelization, as each query is a member of the same slices as the instance of which membership is being decided.
With respect to polynomial kernelizations, the additional requirement is often not much of an issue.
In a typical parameterization~$\eta$, each instance~$x$ has a parameter value~$k$ that satisfies $x \in \eta_k$ and $\asNat(k) \le \length{x}$.
This subsumes the additional requirement.

Ideally, the order on parameterizations as defined in Definition~\ref{def:uniform_order} should preserve the size of kernelizations.
Suppose we are working with a set~$A$ and we have two parameterizations, $\eta$~and~$\zeta$, both members of~$\calL_\cl{FPT}$, that satisfy $\eta \quasile \zeta$.
In Theorem~\ref{thm:filter}, we have seen that $\calF_\cl{FPT}(A)$ is upward closed, meaning that if $A$ is in \cl{FPT} with~$\eta$, it is also in \cl{FPT} with~$\zeta$.
Unfortunately, it is not the case that if $A$ has a Turing kernelization of size~$h$ with respect to~$\eta$, it also has one of size~$h$ with respect to~$\zeta$.
This is because the size of a kernelization is not well-defined with respect to classes of parameterizations that are equivalent in the order on parameterizations.
However, inside a class of equivalent parameterizations, suitable parameterizations can be found.
\begin{theorem}
  Let $\eta$ and $\zeta$ be parameterizations such that $\eta$ is below $\zeta$ in the order on parameterizations.
  If a set~$A$ has a Turing kernelization of size~$h$ with respect to $\eta$, then there is a parameterization~$\zeta'$ such that
  \begin{itemize}
  \item $\zeta'$ is equivalent to $\zeta$ in the order on parameterizations, and
  \item $A$ has a Turing kernelization of size~$h$ with respect to $\zeta'$.
  \end{itemize}
\end{theorem}
\begin{proof}
  Let~$f$ be a computable function bounding $\gap_{\eta, \zeta}$ from above.
  If $f$ does not grow faster than the identity function, a Turing kernelization of size~$h$ with respect to $\eta$ would also be a one of size~$h$ with respect to $\zeta$.
  In that case, the theorem is proven by taking $\zeta' \deq \zeta$.
  Assume, therefore, that $f$ does grow faster than the identity function.
  Denote, for a number~$i$ and string~$k$, the string consisting of the first $i$~bits of~$k$ by $\prefix(i, k)$, and consider the parameterization
  \begin{equation*}
    \zeta' \deq (\{x \st x \in \zeta_{\prefix(f^{-1}(\length{k}), k)}\})_{k \in \binary^+}.
  \end{equation*}
  This definition ensures that $\gap_{\zeta', \zeta}$ is bounded from above by~$f$ and that $\gap_{\zeta, \zeta'}$ is bounded from above by~$f$.
  Hence, $\zeta'$ is equivalent to~$\zeta$ in the order on parameterizations.
  Moreover, the definition is so that $\gap_{\eta, \zeta'}$ is bounded from above by the identity function.
  By our earlier remarks, it follows that $A$ has a Turing kernelization of size~$h$ with respect to~$\zeta'$.
\end{proof}

Unfortunately, a similar argument can be used to shown that the size of a Turing kernelization does not mean much on an equivalence class of parameterizations.
If a set~$A$ has a Turing kernelization of any computable size with respect to a parameterization~$\eta$, then there is a parameterization~$\eta'$ such that
\begin{itemize}
\item $\eta'$ is equivalent to $\eta$ in the order on parameterizations, and
\item $A$ has a \emph{polynomial} Turing kernelization with respect to $\eta'$.
\end{itemize}
The choice of a specific parameterization is therefore important in the study of kernelizations.
As there is no formal definition of what constitutes a \enquote{natural} parameterization, this will always be more of an art than a science.

The queries made by a polynomial Turing kernelizations are generally considered to be reasonably small~\parencite{flum2006parameterized}.
Indeed, finding polynomial Turing kernelizations for various sets has gained significant interest \parencite{guo2007invitation,cygan2015parameterized,fomin2019kernelization}.
As we shall soon see, polynomial many--one kernelizations are strictly less powerful than polynomial Turing kernelizations.
For polynomial kernelizations, a theorem like Theorem~\ref{thm:kernel_fpt} does not exist.

\subsection{Polynomial Turing Kernelizations}
\label{sec:redundancy:polynomial}%
Given Theorem~\ref{thm:kernel_fpt}, we may wonder whether the length of queries made by a kernelization relates to the parameterized running time of a decision procedure.
At least in one direction, such a relationship can be found.
Let $A$ be a set that is decidable in exponential time and for which there is a polynomial Turing kernelization with respect to some parameterization~$\eta$.
We consider the parameterized running time of the parameterized decision procedure for~$A$ that is constructed in the proof of Theorem~\ref{thm:kernel_fpt}.
Deciding queries in exponential time, we find that there must exist a polynomial~$q$ such that the parameter dependence in this running time is of the form $2^{q(\asNat(k))}$.
Of course, the factor in the running time that is dependent on the length of the instance can be bounded by a polynomial, say~$p$.
To summarize, because $A$ is in~\cl{EXP} and has a polynomial Turing kernelization with respect to~$\eta$, it is decidable in time $2^{q(\asNat(k))} \cdot p(\length{x})$ with respect to~$\eta$.

That the converse of this observation fails to hold was proven by \textcite{bodlaender2009problems} for the restricted case of polynomial many--one kernelizations.
Using a different proof technique, we can extend this result to polynomial Turing kernelizations in their full generality.
\begin{theorem}
\label{thm:htop}%
  Let $h$ be a time-constructible function in~$2^{\littleo(n)}$.
  There exists a set~$A$ and parameterization~$\eta$ satisfying
  \begin{itemize}
  \item
    $A$ is in \cl{FPT} with $\eta$, witnessed by a parameterized procedure, taking input of the form $(x, k)$, that has a running time in $\bigO(2^{\asNat(k)} + \length{x})$, yet
  \item
    $A$ admits no Turing kernelization of size~$h$.
  \end{itemize}
  In particular, there is a set that is decidable in time $\bigO(2^{\asNat(k)} + \length{x})$ with respect to a parameterization~$\eta$, but admits no polynomial Turing kernelization.
\end{theorem}
\begin{proof}
  We shall derive the existence of a set~$A$ and parameterization~$\eta$ with the desired properties from the time hierarchy theorem \parencite{hartmanis1965computational,hennie1966two-tape}.
  If the set would have a Turing kernelization of size~$h$, using it in a decision procedure would lead to a speedup ruled out by the time hierarchy theorem.

  Any set for which there is a kernelization of bounded size is in~\cl{P}.
  Hence, we may assume that~$h$ is an unbounded function.
  Consider the time-constructible time bound
  \begin{equation*}
    t(n) \deq 2^{\frac{1}{5} h^{-1}(n)},
  \end{equation*}
  where we define $h^{-1}(n)$ as $\min\{m \st h(m) \ge n\}$.
  The constant $\frac{1}{5}$ in this expression is fairly arbitrary, but chosen to simplify the last part of this proof.
  Additionally, define a parameterization
  \begin{equation*}
    \eta \deq \left(\left\{x \st[\middle] \tfrac{1}{5} h^{-1}(\length{x}) \le \asNat(k)\right\}\right)_{k \in \binary^+}.
  \end{equation*}
  If membership of a string~$x$ in a set~$A$ can be decided in time~$t(\length{x})$, then with respect to~$\eta$ membership in~$A$ can be decided in time~$\bigO(2^{\asNat(k)} + \length{x})$.
  Here, the term~$\length{x}$ serves only to allow for sufficient time to read the entire input.
  It remains to show that there exists such a set~$A$ that lacks a Turing kernelization of size~$h$ with respect to~$\eta$.

  Equivalent to the fact that~$h(n)$ is in $2^{\littleo(n)}$, is the fact that~$h$ is superlogarithmic and thus that~$t$ grows faster than any polynomial.
  Suppose that time~$t$ is required  by any decision procedure for a set~$A$.
  Observe that a Turing kernelization for this set~$A$ is only given a polynomial amount of running time, hence it must make at least one query to its oracle.
  To see why a kernelization for~$A$ with respect to~$\eta$ cannot be of size~$h$, fix a kernelization and let~$p$ be the polynomial bounding its running time.
  Suppose toward a contradiction that the kernelization is of size~$h$.
  We can combine the kernelization with a decision procedure for~$A$ running in time~$t$ to answer oracle queries.
  This yields a parameterized decision procedure converging to~$A$ on~$\eta$ with a running time of~$p(\length{x}) \cdot t(h(\asNat(k)))$.
  By using a parameter value $k$ such that $\asNat(k)$ is at least $\frac{1}{5} h^{-1}(\length{x})$, we can turn this parameterized decision procedure into a regular decision procedure.
  The procedure we end up with is one deciding whether a given string~$x$ is in~$A$, roughly running in time
  \begin{equation*}
    t'(n) \deq p(n) \cdot t(h(\tfrac{1}{5} h^{-1}(n))).
  \end{equation*}

  The proof can now be completed by showing that $t'(n) \log t'(n)$ is in $\littleo(t(n))$.
  In that case, the time hierarchy theorem tells us that there is a set that is decidable in time $t$, but not in time $t'$.
  Thus, the time hierarchy theorem violates our assumption that the kernelization for~$A$ with respect to~$\eta$ that we started out with was of size~$h$.
  Our strategy is to prove that $t'(n)$ is in~$\littleo(\sqrt{t(n)})$.
  Because $\log t'(n)$ would then also be in~$\littleo(\sqrt{t(n)})$, it would follow that the product of the two would indeed be in~$\littleo(t(n))$.
  In proving that $t'(n)$ is in~$\littleo(\sqrt{t(n)})$, we use a similar strategy:
  We verify that both factors in the definition of~$t'(n)$ are in~$\littleo(\sqrt[4]{t(n)})$.

  Earlier, we observed that~$t$ grows faster than any polynomial.
  Therefore, the polynomial factor, $p(n)$, in the definition of~$t'(n)$ is in~$\littleo(\sqrt[4]{t(n)})$.
  All that remains is to show that $t(h(\frac{1}{5} h^{-1}(n)))$ is in $\littleo(\sqrt[4]{t(n)}) = \littleo(2^{\frac{1}{20} h^{-1}(n)})$.
  By our choice of the constant~$\frac{1}{5}$ in the definition of~$t$, this is straightforward.
  We have
  \begin{align*}
    t(h(\tfrac{1}{5} h^{-1}(n))) &= 2^{\frac{1}{5} h^{-1}(h(\frac{1}{5} h^{-1}(n)))} \\
      &= 2^{\frac{1}{25} h^{-1}(n)},
  \end{align*}
  which is in $\littleo(2^{\frac{1}{20} h^{-1}(n)})$ because $h^{-1}$ is an unbounded function.
\end{proof}

While the set of which the above proof establishes the existence is outside~\cl{P}, it is not too unwieldy.
If the kernelization size, $h$, grows linearly or faster, the resulting set is even decidable in linear exponential time.
That is, it is a member of the class
\begin{equation*}
  \cl{E} \deq \bigcup_{c \ge 1} \cltime{$2^{c \cdot n}$}.
\end{equation*}
This is more or less by necessity, since sets that are too far removed from~\cl{E} cannot show the desired behavior.
In fact, the relationship between kernelization size and computational complexity we found earlier can be reversed for sets that are bi"~immune for \cl{E}.
Let $A$ be a set that is bi-immune for \cl{E}, let $\eta$ be a parameterization, and let~$p$ and~$q$ be polynomials.
Furthermore, suppose there is a parameterized procedure that converges to~$A$ on~$\eta$ and, on input $(x, k)$, runs in time $p(\length{x}) \cdot 2^{q(\asNat(k))}$.
We claim that in this case, $A$ must have a polynomial many--one kernelization with respect to~$\eta$.
To see why this is the case, observe that for almost all~$x$ and~$k$ with~$x \in \eta_k$, the expression $p(\length{x}) \cdot 2^{q(\asNat(k))}$ must be superexponential in~$\length{x}$.
A consequence thereof is that $q(\asNat(k))$ must outgrow~$\length{x}$.
Because of this, a procedure that simply queries the string it is given as input counts as a valid polynomial many--one kernelization for~$A$ with respect to $\eta$.

By Theorem~\ref{thm:htop}, we cannot infer the existence of a polynomial Turing kernel by a glance at a parameterized running time.
The theorem settles the unconditional existence of a certain set without a polynomial Turing kernelization.
However, it provides no means to rule out polynomial Turing kernelizations for any particular set that we may be interested in.
Methods for lower-bounding the size of kernelizations exist, but focus mostly on many--one kernelizations.
The most fruitful program for delivering superpolynomial lower bounds on the size of many--one kernelizations was started by \textcite{bodlaender2009problems}.
An overview of the state-of-the-art in these methods is provided by \textcite{kratsch2014recent}, and as an in-depth textbook by \textcite{fomin2019kernelization}.
About Turing kernelizations, far less is known.
The non-existence of polynomial-sized Turing kernelizations has been linked, conditionally, to hardness for a certain class of sets under a specific reduction~\parencite{hermelin2015completeness}.
We shall not go into details about this line of research and focus on a series of unconditional separations instead.
First, we shall show that the adaptive powers of polynomial Turing kernelizations truly distinguish them from polynomial truth-table kernelizations.
\begin{theorem}
\label{thm:ht}%
  There is a set~$A$ and a parameterization~$\eta$ such that $A$ has a polynomial Turing kernelization, but no polynomial truth-table kernelization with respect to~$\eta$.
\end{theorem}
\begin{proof}
  We shall construct the set $A$ as the disjoint union of two sets, and detail the definition of those two sets, $W$ and~$X$, separately.
  Specifically, $A$ is defined via
  \begin{equation*}
    A \deq \{\bits{0}w \st w \in W\} \cup \{\bits{1}x \st x \in X\}.
  \end{equation*}
  We shall define~$X$ and our parameterization~$\eta$ so that $A$ has a polynomial Turing kernelization with respect to~$\eta$.
  The set~$W$ shall be used to make sure that $A$ has no polynomial truth-table kernelization with respect to~$\eta$.

  \paragraph{Ensuring the existence of a polynomial Turing kernelization.}
  Our polynomial Turing kernelization must be adaptive, for we do not want it to be a polynomial truth-table kernelization.
  In order to achieve this, we define a function $s\colon \binary^+ \to \binary^+$ by
  \begin{equation*}
    s(q) \deq \begin{cases}
      \bits{0}q	& \text{if $q \notin W$}, \\
      \bits{1}q	& \text{if $q \in W$}.
    \end{cases}
  \end{equation*}
  Using this function, we build the set~$X$ from the set~$W$ as
  \begin{equation*}
    X \deq \{x \st \log\length{x} \in \bbN \reland \underbrace{(s \circ s \circ \cdots \circ s)}_{(\log\length{x})^2\text{ times}}(\bits{0}^{\log\length{x}}) \in W\}.
  \end{equation*}
  Thus, ultimately, membership of a string~$x$ in~$X$ depends on membership of a string of length $\log\length{x} + (\log\length{x})^2$ in~$W$.
  This construction allows us to define a parameterization with respect to which the set~$A$ has a polynomial Turing kernelization, regardless of~$W$.
  We define
  \begin{equation*}
    \eta \deq \left(\{\bits{0}w \st \length{w} \le \asNat(k)\} \cup \{\bits{1}x \st \log\length{x} \le \asNat(k)\}\right)_{k \in \binary^+}.
  \end{equation*}
  With respect to this parameterization, a polynomial Turing kernelization may query its input when it is of the form $\bits{0}w$.
  For inputs of the form $\bits{1}x$, a polynomial Turing kernelization can compute the appropriate series of strings to query using the function~$s$.
  Note that it is important that the application of~$s$ in the definition of~$X$ is repeated $(\log\length{x})^2$ times and not just $\log\length{x}$ times.
  If we would have repeated the application of~$s$ only $\log\length{x}$ times, the number of strings that would potentially be queried is only $2^{\log\length{x} + 1} = 2 \cdot \length{x}$.
  This number is polynomial in~$\length{x}$, hence a truth-table kernelization could simply query all these strings.
  By repeating the application $(\log\length{x})^2$ we can define~$W$ so that a polynomial kernelization for~$A$ with respect to~$\eta$ is necessarily adaptive.

  \paragraph{Preventing the existence of a polynomial truth-table kernelization.}
  We construct the set~$W$ by diagonalizing against polynomial truth-table kernelizations.
  To ease our task, we adopt a particularly convenient model of computation in the presence of an oracle.
  Let $\phi_1, \phi_2, \phi_3, \ldots$ be an effective enumeration of procedures that make at most one call to an oracle, but may query any number of strings in that one call.
  We may assume that every truth-table kernelization occurs in this list infinitely often.
  To diagonalize against all polynomial truth-table kernelizations, we run each of these procedures for a limited time, allowing only queries of limited length.
  When running some procedure $\phi_i$, the running-time and query-size restriction we employ shall be a polynomial of degree~$i$.

  The set~$W$ is constructed in stages.
  At stage $i \in \bbN$, we set~$n$ to a value that satisfies a few constraints, namely
  \begin{enumerate}
  \item\label{enum:ht:n}
    we have $n^i \le 2^n$ and $i < n$, and
  \item
    no decision about membership in~$W$ is made about any string of length at least~$n$.
  \end{enumerate}
  Having thus set~$n$, we define $x \deq \bits{0}^{2^n}$, which is so that we have $n = \log\length{x}$.
  Next, we run~$\phi_i$ on input~$\bits{1}x$ for $\length{x}^i$ steps.
  In case~$\phi_i$ makes a call to the oracle, let~$S$ be the set of strings it queries.
  If~$S$ includes a string of length greater than~$n^i$, then $\phi_i$ cannot be a truth-table kernelization of size $n^i$.
  Therefore, if~$S$ includes such a long string, $\phi_i$ needs no further attention and we directly move on to the next stage, aborting the current stage.
  This way, by constraint~\ref{enum:ht:n}, we also make sure that $\bits{1}x$ is not a member of~$S$.
  By the bound imposed on the running time of~$\phi_i$, we find that~$S$ contains at most $\length{x}^i = 2^{n \cdot i}$ strings.
  Because of constraint~\ref{enum:ht:n}, this number is strictly less than~$2^{n^2}$, and there must be a string $y \in \binary^{n^2}$ such that the string $\bits{0}y\bits{0}^n$ is not in~$S$.
  We can enforce membership of~$x$ in~$X$ to depend on membership of $\bits{0}^n$ in~$W$.
  Because $\phi_i$ does not query $\bits{0}y\bits{0}^n$, it cannot know whether $y\bits{0}^n$ is a member of~$W$, which gives us the freedom we need to diagonalize.
  Let $b_1, b_2, \ldots, b_{n^2}$ be the bits of~$y$, that is, we have $y = b_{n^2}\cdots b_2b_1$ and answer the queries made by~$\phi_i$ as follows.
  All queries of which the answer is determined by previous stages of our construction of~$W$ are answered accordingly.
  This includes queries of the form~$\bits{1}x$, which are treated in accordance with the definition of~$X$.
  Queries of the form $\bits{0}b_j\cdots b_2b_1\bits{0}^n$, with $j < n^2$, are answered with~$b_{j + 1}$.
  All other queries are answered with~\bits{0}.
  After thus answering the queries in~$S$, we resume~$\phi_i$ and keep running it for the remainder of its allotted $\length{x}^i$ steps.
  Finally, we place $y\bits{0}^n$ in~$W$ if and only if~$\phi_i$ terminated and rejected.
  This ensures that $\bits{1}x$ is a member of~$A$ if and only if~$\phi_i$ rejects it.

  With~$W$ constructed this way, we have made sure that there is no polynomial truth-table kernelization for~$A$ with respect to~$\eta$.
  Suppose that there were such a truth-table kernelization of polynomial size~$q$, running in time~$p$.
  There would then be an index $i$ such that $\phi_i$ codifies this kernelization and, for all $n > i$ we have $p(n + 1) < n^i$ and $q(n) < n^i$.
  At stage~$i$ of the above construction of~$W$, we made sure that the behavior of~$\phi_i$ is in violation with membership in~$A$ for some string~$\bits{1}x$.
  This shows that~$\phi_i$ could not have been a polynomial truth-table kernelization for~$A$ with respect to~$\eta$.
  Note that we simulated~$\phi_i$ for only~$\length{x}^i$ steps, instead of for~$\length{\bits{1}x}^i$ steps, hence we needed to choose~$i$ so that we have $p(n + 1) < n^i$.
\end{proof}

Even with a bound on the length of queries in place, a truth-table kernelization cannot query all strings that are potentially queried by a given Turing kernelization.
This observation lies at the heart of the above proof, and can be summarized as follows.
\slogan{It is not just about the instances you query, but also about those you could have queried.}

Diagonalization is not a common technique in parameterized complexity theory.
This is because it is not possible to diagonalize against parameterized running times, as there is no way to dominate the parameter dependence.
The proof of Theorem~\ref{thm:ht} shows that it is possible to utilize diagonalization \emph{inside} \cl{FPT}.
The running time of a kernelization is polynomial in the length of the input instance, and has no dependency on a parameter value.
This observation can be used to further distinguish between different types of polynomial kernelizations.

\subsection{A Hierarchy of Polynomial Kernelizations}
\label{sec:redundancy:hierarchy}%
The previous two theorems, Theorem~\ref{thm:htop} and Theorem~\ref{thm:ht}, are the beginning of a hierarchy below~\cl{FPT}.
Depending on the ways a kernelization is allowed to access its oracle, a polynomial kernelization may or may not exist.
For convenience, let us define some parameterized complexity classes indexed by various forms of oracle access.
\begin{definition}
  A set~$A$ is in \defkeyat{PKER@\cl{PKER}}{$\cl{PKER}_\textnormal{Turing}$} with parameterization~$\eta$ if there is a polynomial Turing kernelization for~$A$ with respect to~$\eta$.
  When the oracle access is required to be of a restricted kind, this restriction is noted in place of the \enquote{$\textnormal{Turing}$}-subscript.
\end{definition}

With this notational aid, we can summarize a consequence of Theorem~\ref{thm:htop} as stating that the inclusion $\cl{PKER}_\textnormal{Turing} \subset \cl{FPT}$ is proper.
In turn, Theorem~\ref{thm:ht} can be summarized by the inclusion $\cl{PKER}_\textnormal{truth-table} \subset \cl{PKER}_\textnormal{Turing}$.
These two inclusions form the top of a hierarchy between $\cl{PKER}_\textnormal{many--one}$ and \cl{FPT}.

The approach taken in the proof of Theorem~\ref{thm:ht} can be used to obtain other separation results as well.
To distinguish two types of kernelization, we construct a set that has a kernelization of one of the types, but does not have a kernelization of the other type.
These sets are built as the disjoint union of two parts, where one part realizes the positive characteristic and the other the negative characteristic.
In the proof of Theorem~\ref{thm:ht}, we built the hard part, the part preventing the existence of a polynomial truth-table kernelization, by diagonalization.
The diagonalization explicitly targeted polynomial truth-table kernelizations.
However, it is also possible to reuse a single set as the hard part in multiple separations.
This single set must withstand a form of autoreducibility and be very sparse.
In particular, we will require it to have at most logarithmic density.
By this, we mean that if we let $d(n)$ denote the number of elements in the set that are of length at most~$n$, then~$d(n)$ is in~$\bigO(\log n)$.
\begin{lemma}
\label{lem:nonreducible}%
  There is a decidable set~$W$ with at most logarithmic density, for which no approximation that runs in linear exponential time and is allowed to query instances of~$W$ other than its input has an infinite domain.
\end{lemma}
\begin{proof}
  A set~$W$ that is as required can be said to be bi-immune against linear exponential time Turing autoreducibility.
  As is typical for the creation of bi-immune sets, we shall use a finite injury priority construction \parencite[see][Section~2.11]{downey2010algorithmic} for~$W$.

  Let $\phi_1, \phi_2, \phi_3, \ldots$ be an effective enumeration of procedures that can make use of an oracle.
  Contrary to what we did in the proof of Theorem~\ref{thm:ht}, we allow the procedures to make any number of calls to the oracle.
  With each call, the membership of a single string is queried.
  We assign a higher priority to procedures with a lower index and diagonalize against procedures opportunistically.
  As a result, when we diagonalize against a procedure~$\phi_i$ we may have to redo our diagonalization against procedures $\phi_j$ with $i < j$.

  We shall phrase our construction as a procedure that determines membership of strings~$x$ in~$W$, one string at a time.
  For this purpose, we think of~$W$ as a string-indexed array, or characteristic sequence, to which we can assign values.
  Initially, we know nothing about~$W$ and we set it to $(\bits{?}, \bits{?}, \bits{?}, \ldots)$.
  Additionally, we keep track of the indices of procedures we have diagonalized against in a set~$I_\code{done}$ that is initially empty, $\emptyset$.
  As a final bookkeeping device, we maintain, for each string~$x$, the maximum index of a procedure that we may want to diagonalize against at~$x$.
  We codify this as another string-indexed array, $I_\code{max}$.
  By initializing~$I_\code{max}$ uniformly in~$x$ as~$I_\code{max}[x] = \log \log \length{x}$, we shall be able to realize the sparsity required of~$W$.
  Throughout our construction of~$W$, the set $I_\code{done}$ will be finite and both~$I_\code{max}$ and~$W$ will only differ from their initial value at finitely many places.

  For each successive string~$x$, we go through each index~$i$ that satisfies $i < I_\code{max}[x]$ and $i \notin I_\code{done}$ and try to diagonalize against~$\phi_i$.
  We use a set~$Q$ to keep track of the strings that $\phi_i$ queries and of which membership in~$W$ is not yet determined.
  \begin{codelisting}
  \item
    \code{Set} $Q$ to $\emptyset$ and \code{run} $\phi_i$ on input~$x$ for $2^{\length{x}^2}$ steps until any of the following happens:
    \begin{codelisting}
    \item
      \code{In case} $\phi_i$ returns \bits{?} or runs out of time, we cannot diagonalize against~$\phi_i$ at~$x$, and \code{continue} with the next value of~$i$.
    \item
      \code{In case} $\phi_i$ queries a string~$q$, we continue running~$\phi_i$ after using the following to answer the query:
      \begin{codelisting}
      \item
        \code{If} $W[q] \neq \bits{?}$, \code{answer} the query accordingly.
      \item
        \code{Else}, add $q$ to $Q$ and \code{answer} with \bits{0}.
      \end{codelisting}
    \item
      \code{In case} $\phi_i$ terminates and returns $b \in \binary$, we can diagonalize against~$\phi_i$ at~$x$:
      \begin{codelisting}
      \item
        \code{For each} $q \in Q$, \code{set} $W[q]$ to \bits{0} and \code{set} $I_\code{max}[q]$ to $i$.
        This ensures that $W[q]$ may only be changed later on in order to diagonalize against a procedure with a higher priority than $\phi_i$.
      \item\label{code:nonreducible:diagonalize}%
        \code{Set} $W[x]$ to $\bits{1} - b$, so that, with the current state of~$W$, the procedure $\phi_i$ cannot be an approximation for~$W$.
      \item
        \code{Add} $i$ to $I_\code{done}$.
      \item
        \code{Remove} from $I_\code{done}$ all values~$j$ for which we have~$i < j$.
        It is possible that $W[x]$ was previously set to \bits{0} in order to diagonalize against a procedure of lower priority than $\phi_i$.
        These diagonalizations may now be broken.
      \end{codelisting}
    \end{codelisting}
  \end{codelisting}
  If there are no more values of~$i$ to try and we have not decided on membership of~$x$ in~$W$, we set $W[x]$ to \bits{0} and continue with the next string~$x$.

  By running all procedures for $2^{\length{x}^2}$ steps on input~$x$, the allotted time will outgrow any linear exponential time bound.
  Suppose that $\phi_i$ is an approximation for~$W$ that runs in linear exponential time and potentially queries instances of~$W$ other than its input.
  If the domain of~$\phi_i$ is infinite, there must exist a string~$x$ in the domain of~$\phi_i$ with the following properties.
  \begin{itemize}
  \item
    The time taken by~$\phi_i$ on input~$x$ is less than $2^{\length{x}^2}$.
  \item
    When the above procedure considers~$x$, the value of $I_\code{max}[x]$ is greater than~$i$.
  \item
    From the point where the above procedure considers~$x$ onward, no value~$j < i$ will ever be added to $I_\code{done}$.
  \end{itemize}
  The construction of~$W$ diagonalizes against~$\phi_i$ at~$x$ and this diagonalization is never broken after that.
  Thus we may conclude that the domain of~$\phi_i$ cannot be infinite.

  It remains to show that~$W$ has at most logarithmic density.
  Suppose that at some point in the above construction of~$W$ only procedures with an index of at most~$c$ have been considered.
  We claim that at that point at most~$2^c$ strings have been added to~$W$.
  Observe that the only place where a string is added to~$W$ is in step~\ref{code:nonreducible:diagonalize} of the construction of~$W$.
  Thus, at every provisional diagonalization against a procedure~$\phi_i$, at most one string is added to~$W$.
  Additionally, note that $\phi_1$~is diagonalized against at most once, $\phi_2$~is diagonalized against at most twice, $\phi_3$ at most four times, and so on.
  Thus, each~$\phi_i$ contributes at most $2^{i - 1}$~strings to~$W$.
  From this, our claim follows, and because of the way we initialized~$I_\code{max}$, there will be at most~$2^{\log \log n} = \log n$ strings of length at most~$n$ in~$W$.
  Therefore, the set~$W$ meets all requirements of the lemma.
\end{proof}

Not only can the set~$W$ of Lemma~\ref{lem:nonreducible} be reused for a range of separation results, we can do so with a single parameterization.
This parameterization,
\begin{equation}
\label{eq:separation-parameterization}
  \eta \deq \left(\{\bits{0}w \st \length{w} \le \asNat(k)\} \cup \{\bits{1}x \st \log\length{x} \le \asNat(k)\}\right)_{k \in \binary^+},
\end{equation}
was already encountered in the proof of Theorem~\ref{thm:ht}.

A first result we obtain is that the positive nature of many--one kernelizations is a genuine restriction.
\begin{theorem}
\label{thm:hpositive}%
  With respect to the parameterization~$\eta$ defined by~\eqref{eq:separation-parameterization}, there is a set that has a polynomial kernelization that makes at most one query, but no polynomial positive truth-table kernelization.
\end{theorem}
\begin{proof}
  Let $W$ be the set of Lemma~\ref{lem:nonreducible} and consider the set
  \begin{equation*}
    A \deq \{\bits{0}w \st w \in W\} \cup \{\bits{1}x \st \asStr(\length{x}) \notin W\}.
  \end{equation*}
  Observe that the length of~$\asStr(\length{x})$ is logarithmic in~$\length{x}$.
  Therefore, there is a polynomial kernelization for~$A$ with respect to the parameterization~$\eta$ defined by~\eqref{eq:separation-parameterization} that makes at most a single query.
  On the hard part, the strings of the form~$\bits{0}w$, this kernelization queries its input.
  On the redundant part, the strings of the form~$\bits{1}x$, this kernelization queries $\asStr(\length{x})$ and returns the opposite of the answer of the oracle.

  Assuming~$A$ has a polynomial positive truth-table kernelization, $\phi$, we shall define an approximation for~$W$ with an infinite domain.
  This approximation is allowed to query instances of~$W$ other than its input and runs in linear exponential time, contradicting the definition of~$W$ in Lemma~\ref{lem:nonreducible}.
  From this, the theorem follows.

  Observe that, on any input of the form~$\bits{1}x$, the kernelization~$\phi$ does not query its oracle for a string~$\bits{0}w$ for which we have $w = \asStr(\length{x})$.
  This is because if its eventual decision would depend on the answer to such a query, $\phi$ would either be incorrect or not positive.
  Our approximation for~$W$ proceeds as follows on input~$w$.
  \begin{codelisting}
  \item
    \code{Set} $x$ to $\bits{0}^{\asNat(w)}$, so that we have $\bits{1}x \in A \iff w \notin W$.
  \item
    \code{Run} $\phi(\bits{1}x)$ and \code{in case} it queries a string~$q$, respond as follows:
    \begin{codelisting}
    \item\label{code:hpositive:not_self}%
      \code{If} $q$ is of the form~$\bits{1}y$ with~$\length{y} = \length{x}$, \code{return} \bits{?}.
    \item
      \code{Else}, \code{if} $q$ is of the form~$\bits{1}y$, \code{answer} the query in accordance with \emph{non}"~membership of~$\asStr(\length{y})$ in~$W$.
      By the previous \code{if}"~clause, we can be sure that~$\asStr(\length{y})$ differs from~$w$.
      Therefore, this step does not require us to query the oracle for the input string~$w$.
    \item
      \code{Else}, $q$ is of the form~$\bits{0}y$ and we \code{answer} the query in accordance with membership of~$y$ in~$W$.
      By our earlier observation, we once again have~$y \neq w$.
    \end{codelisting}
    \item
      \code{Return} the opposite of the value returned by~$\phi(\bits{1}x)$.
  \end{codelisting}
  By construction, this procedure is an approximation for~$W$.
  The time required by this approximation can be bounded by a polynomial in~$\length{\bits{1}x}$.
  Consequently, it can also be bounded by a linear exponential function of~$\length{w}$, as required.
  Moreover, the approximation does not query the oracle for its input, so all that remains to be shown is that the domain of the approximation is infinite.
  We shall do so by proving that the \code{if}"~clause of step~\ref{code:hpositive:not_self} is only satisfied for finitely many inputs to the approximation.
  This is a direct consequence of the fact that~$\phi$ is a polynomial kernelization with respect to~$\eta$.
  Because of this, $\phi$ is, on input~$\bits{1}x$, only allowed to query strings of which the length can be bounded by a polynomial of~$\log\length{x}$.
  Thus, $\phi$ may query strings of a length equal to that of the input only finitely often.
\end{proof}

Recall that a many--one kernelization is a positive kernelization that makes at most one query.
Therefore, the above theorem implies an inclusion at the bottom of our hierarchy between $\cl{PKER}_\textnormal{many--one}$ and \cl{FPT}.
\begin{corollary}
  We have $\cl{PKER}_\textnormal{many--one} = \cl{PKER}^\textnormal{positive}_\textnormal{$1$ query} \subset \cl{PKER}_\textnormal{$1$ query}$.
\end{corollary}

Next to separations based on whether or not a polynomial kernelization is positive, we find separations based on the number of queries that are permitted.
\begin{theorem}
\label{thm:hc}%
  With respect to the parameterization~$\eta$ defined by~\eqref{eq:separation-parameterization}, for every constant~$c$, there is a set that has a polynomial positive kernelization that makes at most $c + 1$~queries, but no polynomial kernelization that makes at most $c$~queries.
\end{theorem}
\begin{proof}
  Let~$W$ be the set of Lemma~\ref{lem:nonreducible} and consider the sets defined uniformly in~$c \in \bbN$ by
  \begin{equation*}
    A_c \deq \{\bits{0}w \st w \in W\} \cup \left\{\bits{1}x \st[\middle] \bigvee_{i \le c} \Big(\asStr(c \cdot (\length{x} - 1) + i) \in W\Big)\right\}.
  \end{equation*}
  As in Theorem~\ref{thm:ht} and Theorem~\ref{thm:hpositive}, by construction these sets have a specific kernelization with respect to the parameterization~$\eta$ defined by~\eqref{eq:separation-parameterization}.
  In this case, for every value of~$c$, the set $A_c$ has a polynomial positive kernelization that makes at most $c$~queries.
  We shall show that $A_{c + 1}$ does not have a polynomial kernelization that makes at most $c$~queries.
  As in the proof of Theorem~\ref{thm:hpositive}, the proof is a proof by contradiction.
  Like before, the existence of such a kernelization implies the existence of a linear exponential time approximation for~$W$ with an infinite domain.

  Suppose $A_{c + 1}$ has a polynomial kernelization~$\phi$ that makes at most $c$~queries.
  Our approximation for~$W$ proceeds as follows on input~$w$.
  \begin{codelisting}
  \item
    \code{Let} $n$ and $i$ be the unique values such that $i$~is less than $c + 1$ and we have $\asNat(w) = (c + 1) \cdot (n - 1) + i$, and \code{set} $x$ to $\bits{0}^n$.
    This way, if $w$ is a member of~$W$, then $\bits{1}x$ is a member of $A_{c + 1}$.
  \item
    \code{Run} $\phi(\bits{1}x)$ and \code{in case} it queries a string $q$, respond as follows:
    \begin{codelisting}
    \item\label{code:hc:nonw}%
      \code{If} $q$ is of the form $\bits{1}y$ with $\length{y} = \length{x}$, or \code{if} $q$ is of the form $\bits{0}w$, \code{return} \bits{?}.
    \item
      \code{Else}, \code{if} $q$ is of the form $\bits{1}y$, use $c + 1$~queries to~$W$ to determine membership of $\bits{1}y$ in~$A_{c + 1}$ and \code{answer} the query accordingly.
      By the previous \code{if}"~clause, this does not require us to query the oracle for the input string~$w$.
    \item
      \code{Else}, $q$ is of the form $\bits{0}y$ and we \code{answer} the query in accordance with membership of~$y$ in~$W$.
      Again, because of the \code{if}"~clause in step~\ref{code:hc:nonw}, we have $y \neq w$ and we do not need to query the oracle for the input string~$w$.
    \end{codelisting}
  \item
    \code{If} $\phi(\bits{1}x)$ returned \bits{0}, we infer that $w$ cannot be a member of $W$ and \code{return} \bits{0}.
  \item
    \code{Else}, \code{return} \bits{?}.
  \end{codelisting}
  Like in the proof of Theorem~\ref{thm:hpositive}, this defines an approximation for~$W$ that runs in linear exponential time and only queries strings different from its input.
  All that is left is to show that its domain is infinite.
  Because $\phi$ is a polynomial kernelization, there are only finitely many instances for which $\phi$ can make queries of a length equal to that of the input instance.
  Furthermore, observe that the same value is assigned to~$x$ for $c + 1$ different values of~$w$, while $\phi$ can query at most $c$ of those values of~$w$.
  Combined, these observations tell us that the \code{if}"~clause of step~\ref{code:hc:nonw} is only satisfied for finitely many values of~$x$.
  Lastly, if only finitely many values of~$x$ that we consider would be such that $\bits{1}x$ is not in~$A_{c + 1}$, then $W$ would have exponential density.
  Hence, $\phi(\bits{1}x)$ must return~\bits{0} for infinitely many values of~$x$, showing that the domain of the approximation outlined above is infinite.
\end{proof}

The above theorem says that, for every~$c$ and with respect to the parameterization of~\eqref{eq:separation-parameterization}, there is a set in $\cl{PKER}^\textnormal{positive}_\textnormal{$c + 1$ queries}$ that is not in~$\cl{PKER}_\textnormal{$c$ queries}$.
From this, we obtain two strands of our hierarchy.
\begin{corollary}
\label{cor:hc}%
  For every constant~$c$, we have the two proper inclusions $\cl{PKER}^\textnormal{positive}_\textnormal{$c$ queries} \subset \cl{PKER}^\textnormal{positive}_\textnormal{$c + 1$ queries}$ and $\cl{PKER}_\textnormal{$c$ queries} \subset \cl{PKER}_\textnormal{$c + 1$ queries}$.
\end{corollary}

The proofs of our separation results so far, Theorem~\ref{thm:ht}, Theorem~\ref{thm:hpositive}, and Theorem~\ref{thm:hc}, all employed the same proof technique.
Yet, each revolved around a different distinguishing feature of Turing kernelizations.
The proof of the first of these theorems made use of the fact that Turing kernelizations can be \emph{adaptive}, while truth-table kernelizations cannot.
The proof of the second theorem demonstrated that requiring a kernelization to be \emph{positive} is a real restriction of its capabilities.
In the last of these proofs, the same was shown for the \emph{number of queries} that we allow a kernelization to make.
While we distinguished kernelizations that can make a constant number of queries, the result extends to kernelizations where this number grows unbounded.

\begin{theorem}
\label{thm:htt}%
  With respect to the parameterization~$\eta$ defined by~\eqref{eq:separation-parameterization}, there is a set that has a polynomial positive truth-table kernelization, but no polynomial kernelization that makes a number of queries that can be bounded by a constant.
\end{theorem}
\begin{proof}
  Let~$W$ be the set of Lemma~\ref{lem:nonreducible} and consider the set
  \begin{equation*}
    A \deq \{\bits{0}w \st w \in W\} \cup \left\{\bits{1}x \st[\middle] \bigvee_{i \le \length{x}} \left(\asStr\left(\frac{\length{x} \cdot (\length{x} - 1)}{2} + i\right) \in W\right)\right\}.
  \end{equation*}
  Apart from the number of terms in the disjunction, this definition is the same as that of the sets~$A_c$ in the proof of Theorem~\ref{thm:hc}.
  Indeed, the remainder of the proof is mostly the same as well, and we shall only mention where the current proof differs from that of Theorem~\ref{thm:hc}.

  A minor, technical detail is that because of the change in the number of terms in the disjunction, we need a slight change in the approximation for~$W$.
  In order to obtain a suitable string~$x$, the beginning of the approximation should be changed as follows.
  \begin{codelisting}
  \item
    \code{Let} $n$ and $i$ be the unique values such that $i$~is less than $n$ and we have $\asNat(w) = \frac{n \cdot (n - 1)}{2} + i$, and \code{set} $x$ to $\bits{0}^n$.
    This way, if $w$ is a member of~$W$, then $\bits{1}x$ is a member of $A$.
  \end{codelisting}

  To see why the modified approximation too has an infinite domain, two observations are needed.
  First, we note that the number of terms in the disjunction defining the redundant part of~$A$ outgrows any constant.
  Therefore, any polynomial kernelization making no more than a constant number of queries can be run to completion for infinitely many inputs~$\bits{1}x$.
  Next, suppose that only finitely many of the strings~$\bits{1}x$ that our approximation for~$W$ may consider would not be a member of~$A$.
  In that case, $W$ must have at least linear density.
  As $W$ has at most logarithmic density, this means the polynomial kernelization we run must reject infinitely many of our inputs~$\bits{1}x$.
  However, this would mean that our approximation for~$W$ has an infinite domain.
  We conclude that $A$ cannot have a polynomial kernelization with respect to~$\eta$ that makes a number of queries that can be bounded by a constant.
\end{proof}

This theorem places polynomial truth-table kernelizations above those making at most a constant number of queries in our hierarchy.
Assembling our separation results, we can depict our hierarchy as in Figure~\ref{fig:kernel_hierarchy}.
This depiction includes one additional level that we have not discussed yet, namely that of psize kernelizations.
These kernelizations, we shall go into next.

\begin{figure}
  \centering
  \hspace*{-8em}  % A missing node in the picture enlarges the bounding box
  \begin{tikzpicture}
    \graph[layered layout, grow'=up, sibling distance=9em, level distance=1.5cm,
 edges={draw=none}, edge quotes={sloped, allow upside down}]{
      p1/"$\cl{PKER}^\textnormal{positive}_\textnormal{\rlap{$1$ query}}\mathrlap{\:= \cl{PKER}_\textnormal{many--one}}$" -- missing1/"";
      p1 ->["$\subset$"] {
        p2/"$\cl{PKER}^\textnormal{positive}_\textnormal{\rlap{$2$ queries}}$" ->["$\subset$"]
          p3/"$\cl{PKER}^\textnormal{positive}_\textnormal{\rlap{$3$ queries}}$" ->["$\subset$"]
          pdots/"$\vdots$" ->["$\subset$"]
          ppsize/"$\cl{PKER}^\textnormal{positive}_\textnormal{\rlap{psize}}$" ->["$\subset$"]
          ptt/"$\cl{PKER}^\textnormal{positive}_\textnormal{\rlap{truth-table}}$" -- missing2/"",
        "$\cl{PKER}_\textnormal{\rlap{$1$ query}\phantom{psize}}$" ->["$\subset$"]
          2/"$\cl{PKER}_\textnormal{\rlap{$2$ queries}\phantom{psize}}$" ->["$\subset$"]
          3/"$\cl{PKER}_\textnormal{\rlap{$3$ queries}\phantom{psize}}$" ->["$\subset$"]
          "$\vdots$" ->["$\subset$"]
          psize/"$\cl{PKER}_\textnormal{psize}$" ->["$\subset$"]
          tt/"$\cl{PKER}_\textnormal{\rlap{truth-table}\phantom{psize}}$" ->["$\subset$"]
          T/"$\cl{PKER}_\textnormal{\rlap{Turing}\phantom{psize}}$" ->["$\subset$"]
          FPT/"$\cl{FPT}$"
      };
      p2 ->["$\subset$"] 2;
      p3 ->["$\subset$"] 3;
      ppsize ->["$\subset$"] psize;
      ptt ->["$\subset$"] tt;
    };
  \end{tikzpicture}
  \caption{
    A hierarchy of polynomial kernelizations.
    Inclusions from left to right follow from Theorem~\ref{thm:hpositive}.
    The vertical inclusions on the bottom part follow from Corollary~\ref{cor:hc}.
    Those at the top follow from Theorem~\ref{thm:hpsize}, Theorem~\ref{thm:htt}, \ref{thm:ht}, and Theorem~\ref{thm:htop}.
  }
  \label{fig:kernel_hierarchy}
\end{figure}

\subsection{Polynomial Advice}
\label{sec:redundancy:advice}\indexkey{advice|(}%
Let us return for a moment to the interpretation of kernelization as preprocessing.
Imagine we are interested in a set~$A$ and are somehow presented with an instance~$x$ of which we might later on need to know whether or not it is a member of~$A$.
We may find that storage space is a scarce resource, so we seek for alternatives to recording the entire instance.
One way to save on storage space is to decide on membership of~$x$ in~$A$ and only record the membership decision.
This brings the storage cost down from however many bits $x$ is comprised of to just one bit.
However, deciding membership in~$A$ may be a computationally costly affair.
As we may never actually need to know whether the instance is in~$A$ or not, this computational cost is unacceptable.

This is where a many--one kernelization comes in.
If~$A$ has a many--one kernelization with respect to some parameterization~$\eta$, and $\eta$ has a polytime-computable parameter estimator, we are in good shape.
Running the many--one kernelization is a computationally manageable task and gets us an instance that is equivalent to~$x$ with regard to membership in~$A$.
The storage space required to store this equivalent instance can be bounded by a function of the parameter value associated with~$x$ by the parameter estimator.
Especially convenient is the situation where the many--one kernelization is a polynomial many--one kernelization.
In that case, the required storage space can be bounded by a polynomial of the numeric value of the parameter.

The hierarchy of polynomial kernelizations, Figure~\ref{fig:kernel_hierarchy}, shows that there are sets for which no polynomial many--one kernelization exists.
However, these sets may still have, for instance, a polynomial kernelization that makes at most one query.
Such a kernelization could equally well be used in our scenario.
All we have to do is record the query made by the kernelization and whether or not its membership decision is to be inverted.
Doing so again comes with a guarantee on the required storage space that is polynomial in the numeric value of the parameter.

This strategy does not extend to the level of polynomial truth-table kernelizations.
It is true that each of the queries made by a polynomial truth-table kernelization is of a polynomially bounded length.
However, the number of such queries is only bounded to be polynomial in the length of the input instance.
Therefore, a polynomial truth-table kernelization does not guarantee useful preprocessing in terms of storage space requirements.
Worse still, even if the number of queries could be bounded by a polynomial in the numeric parameter value, no such polynomial guarantee is available.
This is because the size of the truth-table, listing the membership decision for all possible replies of the oracle, is exponential in the number of queries.
When the number of queries would be logarithmic in the numeric parameter value, a polynomial truth-table kernelization would be useful for preprocessing.
However, we can do better than that.
\begin{definition}
  A polynomial truth-table kernelization~$\phi$ is a \defkeyat{kernelization!psize}{psize kernelization} if there is a polynomial~$p$ such that, on any input~$(x, k)$
  \begin{itemize}
  \item the number of queries made by~$\phi$ is at most~$p(\asNat(k))$, and
  \item the output of~$\phi$ can be expressed as the output of a circuit of size at most~$p(\asNat(k))$ that takes as input the answers of the oracle to the queries.
  \end{itemize}
  Moreover, the circuits involved must be uniformly computable from the input instances in polynomial time.
\end{definition}

In our scenario where we might, at some point, want to know membership of~$x$ in~$A$, a psize kernelization offers a balance of computational cost and storage cost.
On the one hand, the computational cost of running the kernelization algorithm is polynomial in the length of the instance.
Assuming the thesis by Cobham and Edmonds, this is feasible.
The storage cost, on the other hand, is polynomial in the numeric parameter value.
Instead of recording $x$ itself, we record which strings are queried by the psize kernelization on input~$x$, along with the circuit that ties them together.
This results in recording a polynomial number of strings of polynomial length, together with a circuit of polynomial size.

Some interesting properties of psize kernelization were studied by \textcite[Chapter~5]{weller2013aspects}.
In particular, \citeauthor{weller2013aspects} uncovered how the non-adaptive nature of psize kernelization influences the number of queries that are made.
We highlight the main result, which presents a trade-off between being non-adaptive and making few queries.\indexkey{kernelization!adaptive}
\begin{theorem}[{\textcite[Theorem~5.1]{weller2013aspects}}]
  The following statements about an \cl{NP}"~complete set~$A$, a parameterization~$\eta$, and a polynomial~$p$ are equivalent.
  \begin{itemize}
  \item
    $A$ has a psize kernelization with respect to~$\eta$ that, on any input~$(x, k)$, makes at most $p(\asNat(k))$ queries.
  \item
    $A$ has a polynomial Turing kernelization with respect to~$\eta$ that, on any input~$(x, k)$, makes at most $\log p(\asNat(k))$ queries.
  \end{itemize}
\end{theorem}

Not every polynomial truth-table kernelization is a psize kernelization.
Yet, all polynomial kernelizations that make a number of queries that can be bounded by a constant are psize kernelizations.
Indeed, the psize kernelizations fit in between these levels of our hierarchy of polynomial kernelizations.

\begin{theorem}
\label{thm:htt_psize}%
  With respect to the parameterization~$\eta$ defined by~\eqref{eq:separation-parameterization}, there is a set that has a positive truth-table kernelization, but no psize kernelization.
\end{theorem}
\begin{proof}
  The proof of Theorem~\ref{thm:htt} actually shows something stronger than Theorem~\ref{thm:htt}.
  Let $f\colon \bbN \to \bbN$ be a function such that, for all but finitely many values of~$n$, we have $f(n) < n$.
  The proof of Theorem~\ref{thm:htt} can be applied to polynomial kernelizations that, given an input instance~$\bits{1}x$, make at most $f(\length{x})$~queries.

  With respect to the parameterization~$\eta$ defined by~\eqref{eq:separation-parameterization}, the number of strings a psize kernelization can query on an input of the form~$\bits{1}x$ is polynomial in $\log \length{x}$.
  Any polylogarithmic function~$f$ is so that, for all but finitely many values of~$n$, we have $f(n) < n$.
  Therefore, the proof of Theorem~\ref{thm:htt} also proves the current theorem.
\end{proof}

This separates the polynomial truth-table kernelizations from the psize kernelizations.
Another adaptation of the proof of Theorem~\ref{thm:htt} can be used to separate the psize kernelizations from those making at most a constant number of queries.

\begin{theorem}
\label{thm:hpsize}%
  With respect to the parameterization~$\eta$ defined by~\eqref{eq:separation-parameterization}, there is a set that has a positive psize kernelization, but no polynomial kernelization that makes a number of queries that can be bounded by a constant.
\end{theorem}
\begin{proof}
  So far, the membership of any string~$w$ in~$W$ played a role in the definition of the computationally redundant part of our sets.
  This is, however, not a necessity and the current theorem is more easily proven without such a tidy definition.
  Instead, let~$W$ be the set of Lemma~\ref{lem:nonreducible} and consider the set
  \begin{equation*}
    A \deq \{\bits{0}w \st w \in W\} \cup \left\{\bits{1}x \st[\middle] \bigvee_{i \le \log\length{x}} \left(\asStr\left(\frac{\length{x} \cdot (\length{x} - 1)}{2} + i\right) \in W\right)\right\}.
  \end{equation*}
  This definition is similar to the one used in the proof of Theorem~\ref{thm:htt}, but the number of terms in the disjunction grows more slowly.
  As a result, $A$ is a subset of the set used in the proof of Theorem~\ref{thm:htt}.

  Note that for all~$x$ and~$k$ that satisfy $x \in \eta_k$, where $\eta$ is as in~\eqref{eq:separation-parameterization}, we have $\log \length{x} \le \asNat(k)$.
  Thus, a number of queries that is linear in~$\asNat(k)$ suffices for a polynomial kernelization for~$A$ with respect to~$\eta$.
  The answers to the queries are combined disjunctively.
  Therefore, the dependence of the kernelization on the answers to the queries can be expressed as a circuit of a size that is polynomially bounded in~$\asNat(k)$.
  Indeed, $A$ has a psize kernelization with respect to~$\eta$.

  We show that $A$ does not have a polynomial kernelization that makes a number of queries that can be bounded by a constant in the same way as before.
  This time, the first step in the approximation for~$W$ in the proof of Theorem~\ref{thm:hc} requires a little more tweaking.
  It should be replaced by the following three steps.
  \begin{codelisting}
  \item
    \code{Set} $n$ and $i$ to the unique values such that $i$~is less than $n$ and we have $\asNat(w) = \frac{n \cdot (n - 1)}{2} + i$.
  \item
    \code{If} $i$ is at least $\log n$, then there is no string $\bits{1}x$ such that the definition of~$A$ depends on~$w$ and we can only \code{return} \bits{?}.
  \item
    \code{Set} $x$ to $\bits{0}^n$.
    This way, if $w$ is a member of~$W$, then $\bits{1}x$ is a member of $A$.
  \end{codelisting}

  As~$A$ is a subset of the set used in the proof of Theorem~\ref{thm:htt}, the same reasoning as used there rules out certain kernelizations for~$A$ with respect to $\eta$.
  Specifically, it follows that $A$ does not have a polynomial kernelizations that makes a  number of queries that can be bounded by a constant.
\end{proof}

Combined, the last two theorems isolate the psize~level in our hierarchy, as depicted in Figure~\ref{fig:kernel_hierarchy}.

So far, our main proof technique has been to create a set with a clear-cut distinction between its hard part and its computationally redundant part.
We defined the redundant part of the set so that it could be reduced to the hard part in some specific way.
With psize kernelizations, the amount of information about the hard part available to the kernelization could be said to be bounded polynomially.
This information can be thought of as \defkey{advice} required for deciding the redundant part.
In the study of computability with advice, the amount of advice is typically bounded by a function of the length of instances.
Most prominently, this is the case with the complexity class \cladv{P}{poly}~\parencite{arora2009computational}.
With psize kernelizations, however, the bound on the amount of advice is polynomial in the numeric parameter value.
This in itself suggests that the two notions of polynomial advice, the complexity classes \cladv{P}{poly} and $\cl{PKER}_\textnormal{psize}$, need not have much in common.
Of course, by Corollary~\ref{cor:decidable}, we already know that the two are different, since \cladv{P}{poly} contains undecidable sets, whereas all sets in \cl{FPT} are decidable.
Yet, with respect to the parameterization defined by~\eqref{eq:separation-parameterization}, we can characterize the \emph{decidable} sets in \cladv{P}{poly} by the kernelizations they have.
\begin{theorem}
\label{thm:ppoly-tt}%
  Let $\eta$ be the parameterization defined by~\eqref{eq:separation-parameterization}.
  The following statements about a decidable set~$X$ are equivalent.
  \begin{enumerate}
  \item\label{enum:advice:ppoly}
    $X$ is in \cladv{P}{poly}.
  \item\label{enum:advice:psize}
    There is a set~$W$ such that the set
    \begin{equation*}
      \{\bits{0}w \st w \in W\} \cup \{\bits{1}x \st x \in X\}
    \end{equation*}
    has a linear truth-table kernelization with respect to~$\eta$.
  \end{enumerate}
\end{theorem}
\begin{proof}
$\ref{enum:advice:ppoly} \implies \ref{enum:advice:psize}$.
  Let $\phi$ be a polytime decision procedure taking advice of polynomially bounded length that decides membership in~$X$ and consider the set of pairs of numbers
  \begin{equation*}
    W \deq \{\pair{n}{i} \st \text{the $i$th bit of the advice string for length~$n$ is \bits{1}}\}.
  \end{equation*}
  With this set, a kernelization can retrieve the advice string required by~$\phi$ for an instance of the form~$\bits{1}x$.
  For this, it makes a number of queries that can be bounded by a polynomial in~$\length{x}$.
  It remains to show that the lengths of these queries can be bounded by a linear function in~$\log \length{\bits{1}x}$.
  Suppose that the number of queries made on an input of the form~$\bits{1}x$, where $x$ is of length~$n$, is at most~$n^c$.
  This means that the longest query that is made has length $\length{\pair{n}{n^c}}$.
  Indeed, with the standard encoding of numbers as strings and our pairing function of Section~\ref{sec:preliminaries:binary}, this length can be bounded linearly in $\log n$.
  With that, the bound on the lengths of the queries is proven.

$\ref{enum:advice:psize} \implies \ref{enum:advice:ppoly}$.
  Suppose we have a linear truth-table kernelization for our disjoint union with respect to $\eta$.
  For this kernelization, there is a constant~$c$ such that all queries made on an input of the form $\bits{1}x$ are of a length bounded by~$c \cdot \log \length{x}$.
  This means that there are no more than $2^{c \cdot \log \length{x}} = \length{x}^c$ strings the kernelization could possibly query.
  Hence, we can replace the oracle by a string of $\length{x}^c$ bits where the $i$th bit is~\bits{1} precisely when we have $\asStr(i) \in W$.
  As this string is only dependent on the length of~$x$, and not on $x$ itself, it can serve as polynomial advice, showing that $X$ is in~\cladv{P}{poly}.
\end{proof}

We remark that the second part of the above proof also shows that we could have replaced truth-table by Turing in the statement of the theorem.
A linear truth-table kernelization may query all strings that a linear Turing kernelization could potentially query.

In the context of the above theorem, it is noteworthy that the set constructed in the proof of Theorem~\ref{thm:htt} has a linear truth-table kernelization.
Thus, the strengthening of that theorem, Theorem~\ref{thm:htt_psize}, can be strengthened further.
It can be strengthened to read that there is a set that has a positive \emph{linear} truth-table kernelization, but no psize kernelization.
This, in light of Theorem~\ref{thm:ppoly-tt}, points at a difference between the notions of polynomial advice represented by \cladv{P}{poly} and $\cl{PKER}_\textnormal{psize}$:
There exists a decidable set $X$ in \cladv{P}{poly} such that no set~$W$ exists such that
\begin{equation*}
  \{\bits{0}w \st w \in W\} \cup \{\bits{1}x \st x \in X\}
\end{equation*}
has a psize kernelization with respect to the parameterization~$\eta$ defined by~\eqref{eq:separation-parameterization}.
However, this does not mean that the notion of advice associated with $\cl{PKER}_\textnormal{psize}$ is in any way more stringent than that associated with \cladv{P}{poly}.
\begin{theorem}
\label{thm:ppoly-one}%
  Let $\eta$ be the parameterization defined by~\eqref{eq:separation-parameterization}.
  There exist decidable sets~$W$ and~$X$ such that
  \begin{itemize}
  \item $X$ is not in \cladv{P}{poly}, and
  \item $\{\bits{0}w \st w \in W\} \cup \{\bits{1}x \st x \in X\}$ has a polynomial many--one kernelization with respect to~$\eta$.
  \end{itemize}
\end{theorem}
\begin{proof}
  We denote the string consisting of the first $i$~bits of a string~$x$ by $\prefix(i, x)$, and define~$X$ in terms of~$W$ as
  \begin{equation*}
    X \deq \{x \st \log\length{x} \in \bbN \reland \prefix((\log\length{x})^2, x) \in W\}.
  \end{equation*}
  This definition ensures that $\{\bits{0}w \st w \in W\} \cup \{\bits{1}x \st x \in X\}$ has a polynomial many--one kernelization with respect to~$\eta$.

  Next, we construct $W$ in such a way that $X$ is not in~\cladv{P}{poly}.
  The only instances of~$W$ that influence~$X$ are those of which the length can be written as a square.
  Therefore, we may assume that $W$ only contains strings of which the length is a square.
  Suppose toward a contradiction that $X$ is in~\cladv{P}{poly} and let $\phi$ be a decision procedure for $X$ that takes an advice string as a second argument.
  Using $\phi$, we define a procedure for deciding membership in~$W$ that takes an instance and an advice string as inputs.
  Given a suitable advice string~$a$ for a given instance~$w$, this procedure decides whether $w$ is a member of~$W$.
  \begin{codelisting}
  \item
    \code{If} $\length{w}$ is not a square, \code{return} \bits{0}.
  \item
    \code{Let} $m$ be $2^{\sqrt{\length{w}}} - \length{w}$ and \code{set} $x$ to $w\bits{0}^m$.
    We have $\prefix((\log\length{x})^2, x) = w$, and hence $w$ is a member of~$W$ precisely when $x$ is a member of~$X$.
  \item
    \code{Return} $\phi(x, a)$.
  \end{codelisting}
  The running time required by this procedure is polynomial in $\length{x}$, hence it is in $2^{\bigO(\sqrt{\length{w}})}$.
  By the same token, the length of a suitable advice string for an instance~$w$ is also in $2^{\bigO(\sqrt{\length{w}})}$.
  Note that the length of the string~$x$ constructed in the procedure is only dependent on the length of~$w$.
  As a result, any two instances~$w_1$ and~$w_2$ that have the same length share the same advice string.
  Thus, for any number~$n$, all $2^n$ strings of length~$n$ share the same advice string with a length in~$2^{\bigO(\sqrt{n})}$.
  This allows us to diagonalize against procedures such as the one we just constructed.
  Doing so, we contradict the existence of~$\phi$ and thus the assumption that $X$ is in~\cladv{P}{poly}.

  We construct~$W$ in stages, at each stage resolving membership of all instances of a given length.
  For this, we introduce the characteristic sequence,~$\chi$, of $W$ for a given length,~$n$,
  \begin{align*}
    \chi(n) &\deq (b_w)_{w \in \binary^n}\text{, where we have} \\
    b_w &= \begin{cases}
      \bits{1}	&\text{if $w \in W$}, \\
      \bits{0}	&\text{otherwise}.
    \end{cases}
  \end{align*}
  Our task is thus to determine $\chi(n)$, for all values of~$n$.
  Let $\phi_1, \phi_2, \phi_3, \ldots$ be an effective enumeration of procedures that take two arguments.
  We may assume that each such procedure occurs in this list infinitely often.
  For a procedure $\phi_i$, we consider the time-constrained characteristic sequence for a given length~$n$ and advice string~$a$, defined by
  \begin{align*}
    \chi_i(n, a) &\deq (b_w)_{w \in \binary^n}\text{, where we have} \\
    b_w &= \begin{cases}
      \bits{1}	&\text{if $\phi_i(w, a)$ returns \bits{1} within $2^{\log\length{w} \sqrt{\length{w}}}$ steps}, \\
      \bits{0}	&\text{otherwise}.
    \end{cases}
  \end{align*}
  The bound on the running time, $2^{\log\length{w} \sqrt{\length{w}}}$, was chosen so that it grows faster than any function in $2^{\bigO(\sqrt{\length{w}})}$.
  Using these characteristic sequences, we build~$W$ by doing the following for each length~$n$ in~$\bbN$.
  \begin{codelisting}
  \item
    \code{If} $n$ is not a square, \code{set} $\chi(n)$ to the sequence of length $2^n$ where each item is \bits{0}.
    As we have noted earlier, we may assume that $W$ only contains strings of which the length is a square.
  \item
    \code{Else}, we consider procedure $\phi_{\sqrt{n}}$ for diagonalization:
    \begin{codelisting}
    \item
      We gather the decisions of~$\phi_{\sqrt{n}}$ on strings of length~$n$ for a variety of advice strings and \code{set}
      \begin{equation*}
        H = \{\chi_{\sqrt{n}}(n, a) \st a \in \binary^+ \reland \length{a} < 2^{\log n \sqrt{n}}\}.
      \end{equation*}
      The bound on the length of the advice string is so that it grows faster than any function in~$2^{\bigO(\sqrt{n})}$.
    \item
      Observe that the collection~$H$ contains fewer than $2^{2^{\log n \sqrt{n}}}$ characteristic sequences of $2^n$ items.
      However, there are $2^{2^n}$ such sequences possible.
      Therefore, we can \code{set} $\chi(n)$ to a characteristic sequence of $2^n$ items that is not in~$H$.
    \end{codelisting}
  \end{codelisting}
  This construction of~$W$ rules out the existence of procedure for deciding membership in $W$ that takes advice of length $2^{\bigO(\sqrt{n})}$ and runs in time $2^{\bigO(\sqrt{n})}$.
\end{proof}

Note that a polynomial many--one kernelization is also a psize kernelization.
Because of this, Theorem~\ref{thm:ppoly-tt} and Theorem~\ref{thm:ppoly-one} show that the notions of polynomial advice represented by \cladv{P}{poly} and $\cl{PKER}_\textnormal{psize}$ are different.
Neither notion is more stringent than the other.
\indexkey{advice|)}%

\subsection{Lower Bounds}
\label{sec:redundancy:lower_bounds}%
An immediate consequence of our hierarchy, Figure~\ref{fig:kernel_hierarchy}, is that not all fixed-parameter tractable problems have polynomial kernelizations.
However, with respect to a given parameterization, the (non-)existence of a polynomial kernelization for any particular set may not be easy to establish.
The most fruitful program for deriving superpolynomial lower bounds on the size of many--one kernelizations was started by \textcite{bodlaender2009problems}.
Building on this work, \textcite{dell2014satisfiability} were able to rule out certain improvements of existing polynomial kernelizations.
They do so by establishing, under complexity theoretic assumptions, a minimum amount of communication that is needed with a generalized oracle.
In particular, this means that there cannot be a Turing kernelization of which the sum of the lengths of the queries it makes stays below this minimum.
The lower bounds of \citeauthor{dell2014satisfiability} go beyond psize kernelizations in that the oracle access may be adaptive.

The technique by \textcite{bodlaender2009problems} for obtaining lower bounds on the size of kernelizations does not generalize to Turing kernelizations.
However, an extension to psize kernelizations is feasible.
We shall adapt a later iteration of the technique, as laid out by \textcite[Section~3]{bodlaender2014kernelization}.
For a more complete background of the technique, we refer to the survey by \textcite{kratsch2014recent}, and the textbook by \textcite{fomin2019kernelization}.

Central to the lower bounds engine are two similar-looking classifications of instance aggregation.
The first of these does not involve a parameterization.
\begin{definition}
\label{def:distillation}%
  A \emph{weak \pr{and}"~distillation} (\emph{weak \pr{or}"~distillation}) of a set~$A$ into a set~$B$ is a procedure that\indexkey{distillation}
  \begin{itemize}
  \item receives as input any finite sequence of strings $x_1, x_2, \ldots, x_t$,
  \item uses time polynomial in $\sum_{i \le t} \length{x_i}$, and
  \item outputs a string~$y$ such that
    \begin{itemize}
    \item we have $y \in B$ if and only if for all (any)~$i$ we have $x_i \in A$, and
    \item $\length{y}$ is bounded by a polynomial in $\max_{i \le t} \length{x_i}$.
    \end{itemize}
  \end{itemize}
\end{definition}

Note how the length of the output of a distillation is bounded by a polynomial in the \emph{maximum} length of its inputs and not by the sum of the input lengths.

Originally, distillations where considered where the target set~$B$ was equal to~$A$, hence the \emph{weak} designator in this more general definition.
Similarly, a parameterized counterpart to distillation, \emph{composition}, was originally defined with the same parameterized set as source and target~\parencite{bodlaender2009problems}.
This was later generalized~\parencite{bodlaender2014kernelization}, with the additional change that the source set was considered outside the context of any parameterization.
In the framework of \citeauthor{downey1999parameterized}, this change is significant, because of the distinction between non-parameterized and parameterized sets.
In our framework, parameterizations are distinct entities and the change is not as significant.
\begin{definition}
  An \emph{\pr{and}"~cross"~composition} (\emph{\pr{or}"~cross"~composition}) with respect to a parameterization~$\eta$ of a set~$A$ into a set~$B$ is a procedure that\indexkey{cross-composition}
  \begin{itemize}
  \item receives as input any finite sequence of strings $x_1, x_2, \ldots, x_t$,
  \item uses time polynomial in $\sum_{i \le t} \length{x_i}$, and
  \item outputs a string~$y$ and parameter value~$k$ satisfying $y \in \eta_k$, such that
    \begin{itemize}
    \item we have $y \in B$ if and only if for all (any) $i$ we have $x_i \in A$, and
    \item $\asNat(k)$ is bounded by a polynomial in $\max_{i \le t} \length{x_i} + \log t$.
    \end{itemize}
  \end{itemize}
\end{definition}

Contrary to the definition of cross-composition by \textcite{bodlaender2014kernelization}, we make no mention of a \enquote{polynomial equivalence relation}.
We have left this aspect out to keep our presentation focused.
Nevertheless, those familiar with cross-composition will find no trouble reintroducing the equivalence relation in the upcoming theorem, Theorem~\ref{thm:distillation}.

With cross-composition, a bound is placed on the \emph{parameter value} of the output of the procedure, rather than on the \emph{length} of the output instance.
Conceptually, a bound of this kind makes sense as parameter values serve as a proxy for the computational hardness of instances.
Thus, a set has a cross-composition when instances can be combined efficiently, without an increase in computational hardness.

It was shown by \textcite{bodlaender2009problems,bodlaender2014kernelization} that polynomial many--one kernelizations tie the two ways of aggregating instances together.
We find that the same is true of psize kernelizations.

\begin{theorem}
\label{thm:distillation}%
  Let $A$ be a set that has an \pr{and}"~cross-composition (\pr{or}"~cross-composition) into a set~$B$ with respect to a parameterization~$\eta$.
  If $B$ has a psize kernelization with respect to~$\eta$, then there is a set~$C$ into which $A$ has a weak \pr{and}"~distillation (weak \pr{or}"~distillation).
\end{theorem}
\begin{proof}
  We shall track the proof of \textcite[Theorem~3.4]{bodlaender2014kernelization}, which in turn follows the approach of \textcite[Lemma~2]{bodlaender2009problems}.
  Assuming $B$ has a psize kernelization, we shall define a weak distillation for~$A$.
  The target of this weak distillation shall be the set
  \begin{align*}
    \pr{Circuit}(B) \deq \{\pair{\phi}{(q_i)_{i \le r}} \st &r \in \bbN \reland \text{$\phi$ is a circuit with $r$ inputs, accepting} \\
      &(q_1 \in B, q_2 \in B, \ldots, q_r \in B)\}.
  \end{align*}
  That is, $\pr{Circuit}(B)$ is the set of pairs of a circuit~$\phi$ and a finite sequence of strings $(q_1, q_2, \ldots, q_r)$, such that $\phi$ outputs~\bits{1} when fed $(q_1 \in B, q_2 \in B, \ldots, q_r \in B)$.

  We may assume that the input sequence, $(x_1, x_2, \ldots, x_t)$, of a distillation does not contain any duplicates.
  Indeed, duplicates only make the task of a distillation easier.
  If we define $s \deq \max_{i \le t} \length{x_i}$, we may therefore also assume that we have $t \le 2^s$, and hence that we have $\log t \le s$.
  Our weak distillation of~$A$ into~$\pr{Circuit}(B)$ proceeds as follows on input $(x_1, x_2, \ldots, x_t)$.
  \begin{codelisting}
  \item
    \code{Run} the cross-composition on $(x_1, x_2, \ldots, x_t)$ to obtain a string~$y$ and parameter value~$k$ satisfying $y \in \eta_k$.
    The string~$y$ is so that it is a member of~$B$ precisely when all or any, depending on the type of cross-composition, input instances are in~$A$.
    Furthermore, by our assumption on $\log t$, we find that $\asNat(k)$ can be bounded by a polynomial in~$s$.
  \item
    \code{Run} the psize kernelization for~$B$ on $y$ and $k$ to obtain a circuit~$\phi$ and a finite sequence of query strings $q_1, q_2, \ldots, q_r$.
    By definition of a psize kernelization, the size of the circuit can be bounded by a polynomial in~$\asNat(k)$, and therefore also by a polynomial in~$s$.
    Likewise, both the number of query strings and the length of these strings can be bounded by a polynomial in~$s$.
  \item
    \code{Return} $\pair{\phi}{(q_i)_{i \le r}}$.
    By our previous observations, the length of this pair can be bounded by a polynomial in~$s$.
    We remark that if we did take into account a polynomial equivalence relation in the style of \textcite{bodlaender2014kernelization}, we would at this point have multiple circuits and inputs.
    These circuits would then need to be combined in a way determined by the type of cross-composition.
  \end{codelisting}

  The output of this procedure meets the requirements of a distillation.
  Additionally, the time required for each step can be bounded by a polynomial in $\sum_{i \le t} \length{x_i}$, which also bounds the length of the output at each step.
  Therefore, the above procedure indeed defines a weak distillation of~$A$ into~$\pr{Circuit}(B)$.
\end{proof}

In light of the work of \textcite{bodlaender2014kernelization}, we note two generalizations of the above theorem that can be made.
First, as mentioned before, the definition of a cross-composition can be weakened somewhat.
It need not be possible to aggregate just any finite set of strings.
Instead, it is sufficient if we can quickly partition strings $x_1, x_2, \ldots, x_t$ into a number of subsets that is polynomial in the length of the longest string.
Each of these subsets is then aggregated separately.
This generalization is formalized by means of \enquote{polynomial equivalence relations} by \textcite{bodlaender2014kernelization}.
The second generalization of the above theorem that can be made, is in the requirement of the existence of a psize kernelization.
In the proof, it is not necessary that the queries made by the psize kernelization are queries about membership in~$B$.
Put differently, the psize kernelization may as well have been a reduction from~$B$ to a different set.
Such a relaxed version of kernelization is called \emph{compression} by \textcite{bodlaender2014kernelization}.

The relevance of Theorem~\ref{thm:distillation} lies in its use in ruling out the existence of a psize kernelization for certain sets and parameterizations.
When the framework behind Theorem~\ref{thm:distillation} was first published~\parencite{bodlaender2009problems}, it was already linked to the fact that \cl{NP}"~hard sets are unlikely to have weak distillations.
It was quickly shown by \textcite{fortnow2011infeasibility} that, unless we have $\cl{NP} \subseteq \cladv{coNP}{poly}$, no \cl{NP}"~hard set admits a weak \pr{or}"~distillation.
The conditional absence of weak \pr{and}"~distillations for \cl{NP}"~hard sets was initially left as a conjecture \parencite{bodlaender2009problems}, but eventually proven by \textcite{drucker2015new}.
The inclusion of \cl{NP} in \cladv{coNP}{poly} is deemed unlikely, as it implies a collapse of the polynomial hierarchy to its third level~\parencite{yap1983some}.
These results translate into a technique for obtaining lower bounds on the size of kernelizations.
\begin{corollary}
\label{cor:lower_bound}%
  If an \cl{NP}"~hard language has an \pr{and}"~cross-composition or an \pr{or}"~cross-composition into a set~$A$ with respect to a parameterization~$\eta$, then $A$ does not have a psize kernelization with respect to~$\eta$ unless we have $\cl{NP} \subseteq \cladv{coNP}{poly}$.
\end{corollary}

Many \cl{NP}"~hard sets can be shown to have a cross-composition to themselves with respect to some natural parameterization~\parencite{bodlaender2014kernelization,fomin2019kernelization}.
Accordingly, our hierarchy of polynomial kernelization is not merely relevant to synthetic problems such as the ones used in our proofs.
Of many natural problems, the place in the hierarchy is lower bounded too, adding to the appeal of the hierarchy.

Using the technique of \citeauthor{bodlaender2009problems}, we are unable to rule out any adaptive kernelizations.
This is because of the dependence of the technique on distillations, which do not allow for any adaptive behavior.
Sometimes, however, it is possible to sidestep distillations and directly derive $\cl{NP} \subseteq \cladv{coNP}{poly}$ from the assumed existence of some form of kernelization.
This approach is taken by \citeauthor{dell2014satisfiability} in a stronger form of Corollary~\ref{cor:lower_bound} for \pr{or}"~cross-composition \parencite[Lemma~1]{dell2014satisfiability}.
They too consider the situation where an \cl{NP}"~hard language has an \pr{or}"~cross-composition into a set~$A$ with respect to a parameterization~$\eta$.
Assuming we have $\cl{NP} \subseteq \cladv{coNP}{poly}$, \citeauthor{dell2014satisfiability} rule out a more general class of parameterizations than ruled out by Corollary~\ref{cor:lower_bound}.
In particular, $A$ does not have a polynomial kernelization with respect to~$\eta$ of which the number of queries made can be bounded by a polynomial in the numeric parameter value.
Their proof only applies to \pr{or}"~cross-composition and a similar result for \pr{and}"~cross-composition remains open.

It appears disjunctive instance aggregation has repeatedly yielded results more easily than conjunctive instance aggregation.
Let us digress briefly and summarize the history of the result of \citeauthor{dell2014satisfiability}.
This history can be traced back to results on \pdash{}selective sets by \textcite{ko1983self}.\indexkey{p-selective@\pdash{}selective}
Comparing definitions, we see that having an \pr{or}"~distillation, Definition~\ref{def:distillation}, can be seen as a generalization of being \pdash{}selective, Definition~\ref{def:p-selective}.
Nondeterminism was brought into play by \textcite{hemaspaandra1995nondeterministically}, who show that sets with nondeterministic selector functions are in~\cladv{coNP}{poly}.
The generalization to weak \pr{or}"~distillations goes back to \textcite{fortnow2011infeasibility}.
Finally, \textcite{dell2014satisfiability} add an adaptive character to the result.
